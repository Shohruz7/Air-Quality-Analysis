{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - Data Cleaning\n",
        "\n",
        "This notebook cleans the raw air quality data:\n",
        "- Parse timestamps and set timezone to America/New_York\n",
        "- Normalize units\n",
        "- Flag outliers\n",
        "- Spatial join to boroughs\n",
        "- Save cleaned parquet partitioned by year/month\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw data: /Users/shohruz/Air-Quality-Analysis/data/raw\n",
            "Processed data: /Users/shohruz/Air-Quality-Analysis/data/processed\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "# Data directories\n",
        "PROJECT_ROOT = Path().resolve().parent\n",
        "DATA_RAW = PROJECT_ROOT / \"data\" / \"raw\"\n",
        "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
        "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Raw data: {DATA_RAW}\")\n",
        "print(f\"Processed data: {DATA_PROCESSED}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading: air_quality_raw_20251205_152721.json\n",
            "Loaded 18862 records\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_id</th>\n",
              "      <th>indicator_id</th>\n",
              "      <th>name</th>\n",
              "      <th>measure</th>\n",
              "      <th>measure_info</th>\n",
              "      <th>geo_type_name</th>\n",
              "      <th>geo_join_id</th>\n",
              "      <th>geo_place_name</th>\n",
              "      <th>time_period</th>\n",
              "      <th>start_date</th>\n",
              "      <th>data_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>154596</td>\n",
              "      <td>643</td>\n",
              "      <td>Annual vehicle miles traveled</td>\n",
              "      <td>Million miles</td>\n",
              "      <td>per square mile</td>\n",
              "      <td>CD</td>\n",
              "      <td>313</td>\n",
              "      <td>Coney Island (CD13)</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005-01-01T00:00:00.000</td>\n",
              "      <td>31.85136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>131251</td>\n",
              "      <td>657</td>\n",
              "      <td>Asthma emergency department visits due to PM2.5</td>\n",
              "      <td>Estimated annual rate (age 18+)</td>\n",
              "      <td>per 100,000 adults</td>\n",
              "      <td>UHF42</td>\n",
              "      <td>405</td>\n",
              "      <td>Ridgewood - Forest Hills</td>\n",
              "      <td>2005-2007</td>\n",
              "      <td>2005-01-01T00:00:00.000</td>\n",
              "      <td>19.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>151656</td>\n",
              "      <td>643</td>\n",
              "      <td>Annual vehicle miles traveled</td>\n",
              "      <td>Million miles</td>\n",
              "      <td>per square mile</td>\n",
              "      <td>UHF42</td>\n",
              "      <td>406</td>\n",
              "      <td>Fresh Meadows</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005-01-01T00:00:00.000</td>\n",
              "      <td>61.967759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>131253</td>\n",
              "      <td>657</td>\n",
              "      <td>Asthma emergency department visits due to PM2.5</td>\n",
              "      <td>Estimated annual rate (age 18+)</td>\n",
              "      <td>per 100,000 adults</td>\n",
              "      <td>UHF42</td>\n",
              "      <td>407</td>\n",
              "      <td>Southwest Queens</td>\n",
              "      <td>2005-2007</td>\n",
              "      <td>2005-01-01T00:00:00.000</td>\n",
              "      <td>30.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>130915</td>\n",
              "      <td>650</td>\n",
              "      <td>Respiratory hospitalizations due to PM2.5 (age...</td>\n",
              "      <td>Estimated annual rate</td>\n",
              "      <td>per 100,000 adults</td>\n",
              "      <td>UHF42</td>\n",
              "      <td>405</td>\n",
              "      <td>Ridgewood - Forest Hills</td>\n",
              "      <td>2005-2007</td>\n",
              "      <td>2005-01-01T00:00:00.000</td>\n",
              "      <td>18.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  unique_id indicator_id                                               name  \\\n",
              "0    154596          643                      Annual vehicle miles traveled   \n",
              "1    131251          657    Asthma emergency department visits due to PM2.5   \n",
              "2    151656          643                      Annual vehicle miles traveled   \n",
              "3    131253          657    Asthma emergency department visits due to PM2.5   \n",
              "4    130915          650  Respiratory hospitalizations due to PM2.5 (age...   \n",
              "\n",
              "                           measure        measure_info geo_type_name  \\\n",
              "0                    Million miles     per square mile            CD   \n",
              "1  Estimated annual rate (age 18+)  per 100,000 adults         UHF42   \n",
              "2                    Million miles     per square mile         UHF42   \n",
              "3  Estimated annual rate (age 18+)  per 100,000 adults         UHF42   \n",
              "4            Estimated annual rate  per 100,000 adults         UHF42   \n",
              "\n",
              "  geo_join_id            geo_place_name time_period               start_date  \\\n",
              "0         313       Coney Island (CD13)        2005  2005-01-01T00:00:00.000   \n",
              "1         405  Ridgewood - Forest Hills   2005-2007  2005-01-01T00:00:00.000   \n",
              "2         406             Fresh Meadows        2005  2005-01-01T00:00:00.000   \n",
              "3         407          Southwest Queens   2005-2007  2005-01-01T00:00:00.000   \n",
              "4         405  Ridgewood - Forest Hills   2005-2007  2005-01-01T00:00:00.000   \n",
              "\n",
              "  data_value  \n",
              "0   31.85136  \n",
              "1       19.1  \n",
              "2  61.967759  \n",
              "3       30.6  \n",
              "4       18.3  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the most recent raw JSON file\n",
        "raw_files = sorted(DATA_RAW.glob(\"air_quality_raw_*.json\"))\n",
        "if not raw_files:\n",
        "    raise FileNotFoundError(\"No raw JSON files found. Run 01-ingest.ipynb first.\")\n",
        "\n",
        "latest_file = raw_files[-1]\n",
        "print(f\"Loading: {latest_file.name}\")\n",
        "\n",
        "with open(latest_file, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(f\"Loaded {len(df)} records\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Parse Timestamps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Date range: 2004-12-31 19:00:00-05:00 to 2023-05-31 20:00:00-04:00\n",
            "Timezone: America/New_York\n",
            "\n",
            "Seasons: season\n",
            "Summer       6345\n",
            "Winter       4230\n",
            "Annual       4230\n",
            "2005-2007     480\n",
            "2009-2011     480\n",
            "2012-2014     480\n",
            "2015-2017     480\n",
            "2017-2019     480\n",
            "2005          417\n",
            "2010          321\n",
            "2019          321\n",
            "2011          214\n",
            "2013          144\n",
            "2015          144\n",
            "2014           96\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Time periods: time_period\n",
            "2017-2019      480\n",
            "2005-2007      480\n",
            "2009-2011      480\n",
            "2012-2014      480\n",
            "2015-2017      480\n",
            "Summer 2023    423\n",
            "Summer 2012    423\n",
            "Summer 2015    423\n",
            "Summer 2011    423\n",
            "Summer 2016    423\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start_date</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>date</th>\n",
              "      <th>time_period</th>\n",
              "      <th>season</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2005-01-01T00:00:00.000</td>\n",
              "      <td>2004-12-31 19:00:00-05:00</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>2004</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2005-01-01T00:00:00.000</td>\n",
              "      <td>2004-12-31 19:00:00-05:00</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>2005-2007</td>\n",
              "      <td>2005-2007</td>\n",
              "      <td>2004</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2005-01-01T00:00:00.000</td>\n",
              "      <td>2004-12-31 19:00:00-05:00</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>2004</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2005-01-01T00:00:00.000</td>\n",
              "      <td>2004-12-31 19:00:00-05:00</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>2005-2007</td>\n",
              "      <td>2005-2007</td>\n",
              "      <td>2004</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2005-01-01T00:00:00.000</td>\n",
              "      <td>2004-12-31 19:00:00-05:00</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>2005-2007</td>\n",
              "      <td>2005-2007</td>\n",
              "      <td>2004</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                start_date                 timestamp        date time_period  \\\n",
              "0  2005-01-01T00:00:00.000 2004-12-31 19:00:00-05:00  2004-12-31        2005   \n",
              "1  2005-01-01T00:00:00.000 2004-12-31 19:00:00-05:00  2004-12-31   2005-2007   \n",
              "2  2005-01-01T00:00:00.000 2004-12-31 19:00:00-05:00  2004-12-31        2005   \n",
              "3  2005-01-01T00:00:00.000 2004-12-31 19:00:00-05:00  2004-12-31   2005-2007   \n",
              "4  2005-01-01T00:00:00.000 2004-12-31 19:00:00-05:00  2004-12-31   2005-2007   \n",
              "\n",
              "      season  year  month  \n",
              "0       2005  2004     12  \n",
              "1  2005-2007  2004     12  \n",
              "2       2005  2004     12  \n",
              "3  2005-2007  2004     12  \n",
              "4  2005-2007  2004     12  "
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Parse timestamps and set timezone to America/New_York\n",
        "# Note: start_date represents the start of the time_period (season), not an hourly measurement\n",
        "df['timestamp'] = pd.to_datetime(df['start_date'], errors='coerce')\n",
        "\n",
        "# Set timezone (assume UTC if no timezone, then convert to Eastern)\n",
        "if df['timestamp'].dt.tz is None:\n",
        "    df['timestamp'] = df['timestamp'].dt.tz_localize('UTC')\n",
        "df['timestamp'] = df['timestamp'].dt.tz_convert('America/New_York')\n",
        "\n",
        "# Derive date, month, year from timestamp\n",
        "df['date'] = df['timestamp'].dt.date\n",
        "df['month'] = df['timestamp'].dt.month\n",
        "df['year'] = df['timestamp'].dt.year\n",
        "\n",
        "# Extract season from time_period (e.g., \"Summer 2023\" -> \"Summer\")\n",
        "def extract_season(time_period):\n",
        "    \"\"\"Extract season from time_period string.\"\"\"\n",
        "    if pd.isna(time_period):\n",
        "        return None\n",
        "    parts = str(time_period).split()\n",
        "    if len(parts) >= 1:\n",
        "        return parts[0]  # \"Summer\", \"Winter\", etc.\n",
        "    return None\n",
        "\n",
        "df['season'] = df['time_period'].apply(extract_season)\n",
        "\n",
        "# Note: Since this is seasonal aggregate data, we don't have hour/weekday\n",
        "# Set to None for consistency with schema\n",
        "df['hour'] = None\n",
        "df['weekday'] = None\n",
        "\n",
        "print(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
        "print(f\"Timezone: {df['timestamp'].dt.tz}\")\n",
        "print(f\"\\nSeasons: {df['season'].value_counts()}\")\n",
        "print(f\"\\nTime periods: {df['time_period'].value_counts().head(10)}\")\n",
        "df[['start_date', 'timestamp', 'date', 'time_period', 'season', 'year', 'month']].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Normalize Units\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unit normalization:\n",
            "unit\n",
            "ppb                     8460\n",
            "mcg/m3                  6345\n",
            "per 100,000 adults      1440\n",
            "per square mile          963\n",
            "per 100,000 children     720\n",
            "âµg/m3                   406\n",
            "number                   288\n",
            "per 100,000              240\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Normalized units:\n",
            "unit_normalized\n",
            "ppb                     8460\n",
            "µg/m³                   6345\n",
            "per 100,000 adults      1440\n",
            "per square mile          963\n",
            "per 100,000 children     720\n",
            "âµg/m3                   406\n",
            "number                   288\n",
            "per 100,000              240\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Normalize units\n",
        "# Standardize to µg/m³ for particulates, ppb for gases\n",
        "df['unit'] = df['measure_info'].str.lower().str.strip()\n",
        "\n",
        "# Unit mapping\n",
        "unit_mapping = {\n",
        "    'mcg/m3': 'µg/m³',\n",
        "    'ug/m3': 'µg/m³',\n",
        "    'µg/m³': 'µg/m³',\n",
        "    'micrograms/m3': 'µg/m³',\n",
        "    'ppb': 'ppb',\n",
        "    'parts per billion': 'ppb',\n",
        "    'ppm': 'ppb',  # Will convert values\n",
        "}\n",
        "\n",
        "df['unit_normalized'] = df['unit'].map(unit_mapping).fillna(df['unit'])\n",
        "\n",
        "# Convert ppm to ppb (multiply by 1000)\n",
        "ppm_mask = df['unit'].str.contains('ppm', case=False, na=False)\n",
        "if ppm_mask.any():\n",
        "    df.loc[ppm_mask, 'data_value'] = df.loc[ppm_mask, 'data_value'] * 1000\n",
        "    print(f\"Converted {ppm_mask.sum()} records from ppm to ppb\")\n",
        "\n",
        "print(\"Unit normalization:\")\n",
        "print(df['unit'].value_counts())\n",
        "print(\"\\nNormalized units:\")\n",
        "print(df['unit_normalized'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Flag Outliers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flagged 20 outliers (0.11%)\n",
            "\n",
            "Sample outliers:\n",
            "                         name                            geo_place_name  \\\n",
            "923   Fine particles (PM 2.5)  South Ozone Park and Howard Beach (CD10)   \n",
            "934   Fine particles (PM 2.5)           Kew Gardens and Woodhaven (CD9)   \n",
            "1153  Fine particles (PM 2.5)            Highbridge and Concourse (CD4)   \n",
            "1156  Fine particles (PM 2.5)            Belmont and East Tremont (CD6)   \n",
            "1227  Fine particles (PM 2.5)             Riverdale and Fieldston (CD8)   \n",
            "1254   Nitrogen dioxide (NO2)                 Clinton and Chelsea (CD4)   \n",
            "1305   Nitrogen dioxide (NO2)          Greenwich Village and Soho (CD2)   \n",
            "1412   Nitrogen dioxide (NO2)                  Financial District (CD1)   \n",
            "1439  Fine particles (PM 2.5)      Fordham and University Heights (CD5)   \n",
            "1443  Fine particles (PM 2.5)     Kingsbridge Heights and Bedford (CD7)   \n",
            "\n",
            "      data_value                 timestamp  \n",
            "923        12.60 2008-11-30 19:00:00-05:00  \n",
            "934        13.24 2008-11-30 19:00:00-05:00  \n",
            "1153       15.31 2008-11-30 19:00:00-05:00  \n",
            "1156       14.75 2008-11-30 19:00:00-05:00  \n",
            "1227       14.65 2008-11-30 19:00:00-05:00  \n",
            "1254       40.88 2008-11-30 19:00:00-05:00  \n",
            "1305       39.68 2008-11-30 19:00:00-05:00  \n",
            "1412       41.26 2008-11-30 19:00:00-05:00  \n",
            "1439       15.65 2008-11-30 19:00:00-05:00  \n",
            "1443       14.97 2008-11-30 19:00:00-05:00  \n"
          ]
        }
      ],
      "source": [
        "# Flag outliers using z-score method (grouped by pollutant and station)\n",
        "# Ensure data_value is numeric before outlier detection\n",
        "if df['data_value'].dtype == 'object':\n",
        "    df['data_value'] = pd.to_numeric(df['data_value'], errors='coerce')\n",
        "\n",
        "df['is_outlier'] = False\n",
        "\n",
        "# Only process groups with valid numeric data\n",
        "for (pollutant, station), group in df.groupby(['name', 'geo_join_id']):\n",
        "    # Filter out NaN values for this group\n",
        "    group_clean = group[group['data_value'].notna()]\n",
        "    \n",
        "    if len(group_clean) < 2:  # Need at least 2 values to calculate std\n",
        "        continue\n",
        "    \n",
        "    mean = group_clean['data_value'].mean()\n",
        "    std = group_clean['data_value'].std()\n",
        "    \n",
        "    if std > 0:\n",
        "        z_scores = np.abs((group_clean['data_value'] - mean) / std)\n",
        "        outlier_mask = z_scores > 3.0\n",
        "        df.loc[outlier_mask.index, 'is_outlier'] = outlier_mask.values\n",
        "\n",
        "outlier_count = df['is_outlier'].sum()\n",
        "print(f\"Flagged {outlier_count} outliers ({outlier_count/len(df)*100:.2f}%)\")\n",
        "\n",
        "# Show some outliers\n",
        "if outlier_count > 0:\n",
        "    print(\"\\nSample outliers:\")\n",
        "    print(df[df['is_outlier']][['name', 'geo_place_name', 'data_value', 'timestamp']].head(10))\n",
        "else:\n",
        "    print(\"No outliers detected.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Extract Station Metadata and Boroughs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Borough distribution:\n",
            "borough\n",
            "Unknown          7990\n",
            "Staten Island    3187\n",
            "Queens           2326\n",
            "Brooklyn         2228\n",
            "Manhattan        1775\n",
            "Bronx            1356\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Geo types: geo_type_name\n",
            "UHF42       7392\n",
            "CD          6844\n",
            "UHF34       3570\n",
            "Borough      880\n",
            "Citywide     176\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Unknown boroughs: ['Coney Island (CD13)' 'Ridgewood - Forest Hills' 'Fresh Meadows'\n",
            " 'Willowbrook' 'Stapleton - St. George'\n",
            " 'Hillcrest and Fresh Meadows (CD8)' 'Port Richmond'\n",
            " 'High Bridge - Morrisania' 'Hunts Point - Mott Haven'\n",
            " 'Rego Park and Forest Hills (CD6)']\n"
          ]
        }
      ],
      "source": [
        "# Extract borough from location name and geo_type_name\n",
        "def extract_borough(location_name, geo_type_name):\n",
        "    \"\"\"Extract borough from location name and geo_type.\"\"\"\n",
        "    # If geo_type is Borough, the location_name is the borough\n",
        "    if pd.notna(geo_type_name) and str(geo_type_name).lower() == 'borough':\n",
        "        return str(location_name).title()\n",
        "    \n",
        "    if pd.isna(location_name):\n",
        "        return \"Unknown\"\n",
        "    \n",
        "    location_lower = str(location_name).lower()\n",
        "    \n",
        "    # Direct borough mentions\n",
        "    boroughs = {\n",
        "        'manhattan': 'Manhattan',\n",
        "        'brooklyn': 'Brooklyn',\n",
        "        'queens': 'Queens',\n",
        "        'bronx': 'Bronx',\n",
        "        'staten island': 'Staten Island',\n",
        "        'staten': 'Staten Island',\n",
        "        'si': 'Staten Island'\n",
        "    }\n",
        "    \n",
        "    for key, value in boroughs.items():\n",
        "        if key in location_lower:\n",
        "            return value\n",
        "    \n",
        "    # Heuristics based on location patterns\n",
        "    if any(x in location_lower for x in ['harlem', 'midtown', 'upper east', 'upper west', 'chelsea', 'soho']):\n",
        "        return 'Manhattan'\n",
        "    if any(x in location_lower for x in ['flatbush', 'crown heights', 'sunset park', 'bay ridge', 'bensonhurst']):\n",
        "        return 'Brooklyn'\n",
        "    if any(x in location_lower for x in ['astoria', 'flushing', 'bayside', 'jamaica', 'queens']):\n",
        "        return 'Queens'\n",
        "    if any(x in location_lower for x in ['bronx', 'throgs neck', 'fordham', 'pelham']):\n",
        "        return 'Bronx'\n",
        "    if any(x in location_lower for x in ['tottenville', 'great kills', 'staten']):\n",
        "        return 'Staten Island'\n",
        "    \n",
        "    return \"Unknown\"\n",
        "\n",
        "# Create station metadata\n",
        "df['station_id'] = df['geo_join_id'].astype(str)  # Keep as string to handle composite IDs\n",
        "df['station_name'] = df['geo_place_name']\n",
        "df['geo_type'] = df['geo_type_name']  # Keep geo_type for reference\n",
        "df['borough'] = df.apply(lambda row: extract_borough(row['geo_place_name'], row['geo_type_name']), axis=1)\n",
        "\n",
        "print(\"Borough distribution:\")\n",
        "print(df['borough'].value_counts())\n",
        "print(f\"\\nGeo types: {df['geo_type_name'].value_counts()}\")\n",
        "print(f\"\\nUnknown boroughs: {df[df['borough'] == 'Unknown']['geo_place_name'].unique()[:10]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Create Final Tidy Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned dataset shape: (18862, 18)\n",
            "\n",
            "Columns: ['timestamp', 'date', 'hour', 'weekday', 'year', 'month', 'season', 'time_period', 'pollutant', 'value', 'unit', 'station_id', 'station_name', 'geo_type', 'lat', 'lon', 'borough', 'is_outlier']\n",
            "\n",
            "Pollutants: ['Annual vehicle miles traveled'\n",
            " 'Asthma emergency department visits due to PM2.5'\n",
            " 'Respiratory hospitalizations due to PM2.5 (age 20+)'\n",
            " 'Asthma hospitalizations due to Ozone'\n",
            " 'Outdoor Air Toxics - Formaldehyde'\n",
            " 'Asthma emergency departments visits due to Ozone'\n",
            " 'Annual vehicle miles traveled (cars)' 'Outdoor Air Toxics - Benzene'\n",
            " 'Annual vehicle miles traveled (trucks)' 'Deaths due to PM2.5'\n",
            " 'Cardiac and respiratory deaths due to Ozone'\n",
            " 'Cardiovascular hospitalizations due to PM2.5 (age 40+)' 'NO2' 'PM2.5'\n",
            " 'O3' 'Boiler Emissions- Total SO2 Emissions'\n",
            " 'Boiler Emissions- Total PM2.5 Emissions'\n",
            " 'Boiler Emissions- Total NOx Emissions']\n",
            "\n",
            "Sample data:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>date</th>\n",
              "      <th>hour</th>\n",
              "      <th>weekday</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>season</th>\n",
              "      <th>time_period</th>\n",
              "      <th>pollutant</th>\n",
              "      <th>value</th>\n",
              "      <th>unit</th>\n",
              "      <th>station_id</th>\n",
              "      <th>station_name</th>\n",
              "      <th>geo_type</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>borough</th>\n",
              "      <th>is_outlier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2004-12-31 19:00:00-05:00</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2004</td>\n",
              "      <td>12</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>Annual vehicle miles traveled</td>\n",
              "      <td>31.851360</td>\n",
              "      <td>per square mile</td>\n",
              "      <td>313</td>\n",
              "      <td>Coney Island (CD13)</td>\n",
              "      <td>CD</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2004-12-31 19:00:00-05:00</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2004</td>\n",
              "      <td>12</td>\n",
              "      <td>2005-2007</td>\n",
              "      <td>2005-2007</td>\n",
              "      <td>Asthma emergency department visits due to PM2.5</td>\n",
              "      <td>19.100000</td>\n",
              "      <td>per 100,000 adults</td>\n",
              "      <td>405</td>\n",
              "      <td>Ridgewood - Forest Hills</td>\n",
              "      <td>UHF42</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2004-12-31 19:00:00-05:00</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2004</td>\n",
              "      <td>12</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>Annual vehicle miles traveled</td>\n",
              "      <td>61.967759</td>\n",
              "      <td>per square mile</td>\n",
              "      <td>406</td>\n",
              "      <td>Fresh Meadows</td>\n",
              "      <td>UHF42</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2004-12-31 19:00:00-05:00</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2004</td>\n",
              "      <td>12</td>\n",
              "      <td>2005-2007</td>\n",
              "      <td>2005-2007</td>\n",
              "      <td>Asthma emergency department visits due to PM2.5</td>\n",
              "      <td>30.600000</td>\n",
              "      <td>per 100,000 adults</td>\n",
              "      <td>407</td>\n",
              "      <td>Southwest Queens</td>\n",
              "      <td>UHF42</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Queens</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2004-12-31 19:00:00-05:00</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2004</td>\n",
              "      <td>12</td>\n",
              "      <td>2005-2007</td>\n",
              "      <td>2005-2007</td>\n",
              "      <td>Respiratory hospitalizations due to PM2.5 (age...</td>\n",
              "      <td>18.300000</td>\n",
              "      <td>per 100,000 adults</td>\n",
              "      <td>405</td>\n",
              "      <td>Ridgewood - Forest Hills</td>\n",
              "      <td>UHF42</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  timestamp        date  hour weekday  year  month     season  \\\n",
              "0 2004-12-31 19:00:00-05:00  2004-12-31  None    None  2004     12       2005   \n",
              "1 2004-12-31 19:00:00-05:00  2004-12-31  None    None  2004     12  2005-2007   \n",
              "2 2004-12-31 19:00:00-05:00  2004-12-31  None    None  2004     12       2005   \n",
              "3 2004-12-31 19:00:00-05:00  2004-12-31  None    None  2004     12  2005-2007   \n",
              "4 2004-12-31 19:00:00-05:00  2004-12-31  None    None  2004     12  2005-2007   \n",
              "\n",
              "  time_period                                          pollutant      value  \\\n",
              "0        2005                      Annual vehicle miles traveled  31.851360   \n",
              "1   2005-2007    Asthma emergency department visits due to PM2.5  19.100000   \n",
              "2        2005                      Annual vehicle miles traveled  61.967759   \n",
              "3   2005-2007    Asthma emergency department visits due to PM2.5  30.600000   \n",
              "4   2005-2007  Respiratory hospitalizations due to PM2.5 (age...  18.300000   \n",
              "\n",
              "                 unit station_id              station_name geo_type   lat  \\\n",
              "0     per square mile        313       Coney Island (CD13)       CD  None   \n",
              "1  per 100,000 adults        405  Ridgewood - Forest Hills    UHF42  None   \n",
              "2     per square mile        406             Fresh Meadows    UHF42  None   \n",
              "3  per 100,000 adults        407          Southwest Queens    UHF42  None   \n",
              "4  per 100,000 adults        405  Ridgewood - Forest Hills    UHF42  None   \n",
              "\n",
              "    lon  borough  is_outlier  \n",
              "0  None  Unknown       False  \n",
              "1  None  Unknown       False  \n",
              "2  None  Unknown       False  \n",
              "3  None   Queens       False  \n",
              "4  None  Unknown       False  "
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Select and rename columns to match required schema\n",
        "# Required: timestamp, date, hour, pollutant, value, unit, station_id, station_name, lat, lon, borough, year, month\n",
        "\n",
        "df_clean = df[[\n",
        "    'timestamp', 'date', 'hour', 'weekday', 'month', 'year', 'season', 'time_period',\n",
        "    'name', 'data_value', 'unit_normalized',\n",
        "    'station_id', 'station_name', 'geo_type', 'borough',\n",
        "    'is_outlier'\n",
        "]].copy()\n",
        "\n",
        "# Rename columns\n",
        "df_clean = df_clean.rename(columns={\n",
        "    'name': 'pollutant',\n",
        "    'data_value': 'value',\n",
        "    'unit_normalized': 'unit'\n",
        "})\n",
        "\n",
        "# Clean pollutant names (simplify)\n",
        "df_clean['pollutant'] = df_clean['pollutant'].str.replace('Fine particles (PM 2.5)', 'PM2.5', regex=False)\n",
        "df_clean['pollutant'] = df_clean['pollutant'].str.replace('Nitrogen dioxide (NO2)', 'NO2', regex=False)\n",
        "df_clean['pollutant'] = df_clean['pollutant'].str.replace('Ozone (O3)', 'O3', regex=False)\n",
        "\n",
        "# Note: lat/lon not in original dataset - would need spatial join with station locations\n",
        "# For now, set to None\n",
        "df_clean['lat'] = None\n",
        "df_clean['lon'] = None\n",
        "\n",
        "# Reorder columns\n",
        "df_clean = df_clean[[\n",
        "    'timestamp', 'date', 'hour', 'weekday', 'year', 'month', 'season', 'time_period',\n",
        "    'pollutant', 'value', 'unit',\n",
        "    'station_id', 'station_name', 'geo_type', 'lat', 'lon', 'borough',\n",
        "    'is_outlier'\n",
        "]]\n",
        "\n",
        "print(f\"Cleaned dataset shape: {df_clean.shape}\")\n",
        "print(f\"\\nColumns: {list(df_clean.columns)}\")\n",
        "print(f\"\\nPollutants: {df_clean['pollutant'].unique()}\")\n",
        "print(f\"\\nSample data:\")\n",
        "df_clean.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values:\n",
            "timestamp           0\n",
            "date                0\n",
            "hour            18862\n",
            "weekday         18862\n",
            "year                0\n",
            "month               0\n",
            "season              0\n",
            "time_period         0\n",
            "pollutant           0\n",
            "value               0\n",
            "unit                0\n",
            "station_id          0\n",
            "station_name        0\n",
            "geo_type            0\n",
            "lat             18862\n",
            "lon             18862\n",
            "borough             0\n",
            "is_outlier          0\n",
            "dtype: int64\n",
            "\n",
            "Total rows: 18862\n",
            "Rows with missing critical values: 0\n",
            "Rows after removing missing critical values: 18862\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values:\")\n",
        "print(df_clean.isnull().sum())\n",
        "print(f\"\\nTotal rows: {len(df_clean)}\")\n",
        "print(f\"Rows with missing critical values: {df_clean[['timestamp', 'value', 'pollutant']].isnull().any(axis=1).sum()}\")\n",
        "\n",
        "# Remove rows with missing critical values\n",
        "df_clean = df_clean.dropna(subset=['timestamp', 'value', 'pollutant'])\n",
        "print(f\"Rows after removing missing critical values: {len(df_clean)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Save Processed Parquet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved to: /Users/shohruz/Air-Quality-Analysis/data/processed/measurements.parquet\n",
            "File size: 0.15 MB\n",
            "Saved partitioned data to: /Users/shohruz/Air-Quality-Analysis/data/processed/measurements_partitioned\n",
            "\n",
            "Verification: Loaded 18862 records\n",
            "Columns: ['timestamp', 'date', 'hour', 'weekday', 'year', 'month', 'season', 'time_period', 'pollutant', 'value', 'unit', 'station_id', 'station_name', 'geo_type', 'lat', 'lon', 'borough', 'is_outlier']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>date</th>\n",
              "      <th>hour</th>\n",
              "      <th>weekday</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>season</th>\n",
              "      <th>time_period</th>\n",
              "      <th>pollutant</th>\n",
              "      <th>value</th>\n",
              "      <th>unit</th>\n",
              "      <th>station_id</th>\n",
              "      <th>station_name</th>\n",
              "      <th>geo_type</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>borough</th>\n",
              "      <th>is_outlier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2004-12-31 19:00:00-05:00</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2004</td>\n",
              "      <td>12</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>Annual vehicle miles traveled</td>\n",
              "      <td>31.851360</td>\n",
              "      <td>per square mile</td>\n",
              "      <td>313</td>\n",
              "      <td>Coney Island (CD13)</td>\n",
              "      <td>CD</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2004-12-31 19:00:00-05:00</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2004</td>\n",
              "      <td>12</td>\n",
              "      <td>2005-2007</td>\n",
              "      <td>2005-2007</td>\n",
              "      <td>Asthma emergency department visits due to PM2.5</td>\n",
              "      <td>19.100000</td>\n",
              "      <td>per 100,000 adults</td>\n",
              "      <td>405</td>\n",
              "      <td>Ridgewood - Forest Hills</td>\n",
              "      <td>UHF42</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2004-12-31 19:00:00-05:00</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2004</td>\n",
              "      <td>12</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>Annual vehicle miles traveled</td>\n",
              "      <td>61.967759</td>\n",
              "      <td>per square mile</td>\n",
              "      <td>406</td>\n",
              "      <td>Fresh Meadows</td>\n",
              "      <td>UHF42</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2004-12-31 19:00:00-05:00</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2004</td>\n",
              "      <td>12</td>\n",
              "      <td>2005-2007</td>\n",
              "      <td>2005-2007</td>\n",
              "      <td>Asthma emergency department visits due to PM2.5</td>\n",
              "      <td>30.600000</td>\n",
              "      <td>per 100,000 adults</td>\n",
              "      <td>407</td>\n",
              "      <td>Southwest Queens</td>\n",
              "      <td>UHF42</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Queens</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2004-12-31 19:00:00-05:00</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2004</td>\n",
              "      <td>12</td>\n",
              "      <td>2005-2007</td>\n",
              "      <td>2005-2007</td>\n",
              "      <td>Respiratory hospitalizations due to PM2.5 (age...</td>\n",
              "      <td>18.300000</td>\n",
              "      <td>per 100,000 adults</td>\n",
              "      <td>405</td>\n",
              "      <td>Ridgewood - Forest Hills</td>\n",
              "      <td>UHF42</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  timestamp        date  hour weekday  year  month     season  \\\n",
              "0 2004-12-31 19:00:00-05:00  2004-12-31  None    None  2004     12       2005   \n",
              "1 2004-12-31 19:00:00-05:00  2004-12-31  None    None  2004     12  2005-2007   \n",
              "2 2004-12-31 19:00:00-05:00  2004-12-31  None    None  2004     12       2005   \n",
              "3 2004-12-31 19:00:00-05:00  2004-12-31  None    None  2004     12  2005-2007   \n",
              "4 2004-12-31 19:00:00-05:00  2004-12-31  None    None  2004     12  2005-2007   \n",
              "\n",
              "  time_period                                          pollutant      value  \\\n",
              "0        2005                      Annual vehicle miles traveled  31.851360   \n",
              "1   2005-2007    Asthma emergency department visits due to PM2.5  19.100000   \n",
              "2        2005                      Annual vehicle miles traveled  61.967759   \n",
              "3   2005-2007    Asthma emergency department visits due to PM2.5  30.600000   \n",
              "4   2005-2007  Respiratory hospitalizations due to PM2.5 (age...  18.300000   \n",
              "\n",
              "                 unit station_id              station_name geo_type   lat  \\\n",
              "0     per square mile        313       Coney Island (CD13)       CD  None   \n",
              "1  per 100,000 adults        405  Ridgewood - Forest Hills    UHF42  None   \n",
              "2     per square mile        406             Fresh Meadows    UHF42  None   \n",
              "3  per 100,000 adults        407          Southwest Queens    UHF42  None   \n",
              "4  per 100,000 adults        405  Ridgewood - Forest Hills    UHF42  None   \n",
              "\n",
              "    lon  borough  is_outlier  \n",
              "0  None  Unknown       False  \n",
              "1  None  Unknown       False  \n",
              "2  None  Unknown       False  \n",
              "3  None   Queens       False  \n",
              "4  None  Unknown       False  "
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save as single parquet file\n",
        "parquet_path = DATA_PROCESSED / \"measurements.parquet\"\n",
        "df_clean.to_parquet(parquet_path, index=False, engine='pyarrow')\n",
        "print(f\"Saved to: {parquet_path}\")\n",
        "print(f\"File size: {parquet_path.stat().st_size / 1024 / 1024:.2f} MB\")\n",
        "\n",
        "# Also save partitioned by year/month for large datasets\n",
        "partition_dir = DATA_PROCESSED / \"measurements_partitioned\"\n",
        "df_clean.to_parquet(\n",
        "    partition_dir,\n",
        "    partition_cols=['year', 'month'],\n",
        "    engine='pyarrow',\n",
        "    index=False\n",
        ")\n",
        "print(f\"Saved partitioned data to: {partition_dir}\")\n",
        "\n",
        "# Verify it loads correctly\n",
        "df_test = pd.read_parquet(parquet_path)\n",
        "print(f\"\\nVerification: Loaded {len(df_test)} records\")\n",
        "print(f\"Columns: {list(df_test.columns)}\")\n",
        "df_test.head()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
