{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 - Exploratory Data Analysis\n",
        "\n",
        "This notebook performs EDA on the cleaned air quality data and determines dashboard aggregations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed data: /Users/shohruz/Air-Quality-Analysis/data/processed\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Data directory\n",
        "PROJECT_ROOT = Path().resolve().parent\n",
        "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
        "\n",
        "print(f\"Processed data: {DATA_PROCESSED}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/Users/shohruz/Air-Quality-Analysis/data/processed/measurements.parquet'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load cleaned data\u001b[39;00m\n\u001b[32m      2\u001b[39m parquet_path = DATA_PROCESSED / \u001b[33m\"\u001b[39m\u001b[33mmeasurements.parquet\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparquet_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpyarrow\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m records\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDate range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m].min()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m].max()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parquet.py:670\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    667\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    668\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m670\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parquet.py:265\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    263\u001b[39m     to_pandas_kwargs[\u001b[33m\"\u001b[39m\u001b[33msplit_blocks\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m path_or_handle, handles, filesystem = \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    272\u001b[39m     pa_table = \u001b[38;5;28mself\u001b[39m.api.parquet.read_table(\n\u001b[32m    273\u001b[39m         path_or_handle,\n\u001b[32m    274\u001b[39m         columns=columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    277\u001b[39m         **kwargs,\n\u001b[32m    278\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parquet.py:139\u001b[39m, in \u001b[36m_get_path_or_handle\u001b[39m\u001b[34m(path, fs, storage_options, mode, is_dir)\u001b[39m\n\u001b[32m    129\u001b[39m handles = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    131\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[32m    132\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[32m   (...)\u001b[39m\u001b[32m    137\u001b[39m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[32m    138\u001b[39m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m     fs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    143\u001b[39m     path_or_handle = handles.handle\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/common.py:872\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    863\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    864\u001b[39m             handle,\n\u001b[32m    865\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    868\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    869\u001b[39m         )\n\u001b[32m    870\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    871\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m872\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    873\u001b[39m     handles.append(handle)\n\u001b[32m    875\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/shohruz/Air-Quality-Analysis/data/processed/measurements.parquet'"
          ]
        }
      ],
      "source": [
        "# Load cleaned data\n",
        "parquet_path = DATA_PROCESSED / \"measurements.parquet\"\n",
        "df = pd.read_parquet(parquet_path, engine='pyarrow')\n",
        "\n",
        "print(f\"Loaded {len(df)} records\")\n",
        "print(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
        "print(f\"\\nPollutants: {df['pollutant'].unique()}\")\n",
        "print(f\"\\nBoroughs: {df['borough'].unique()}\")\n",
        "print(f\"\\nStations: {df['station_id'].nunique()}\")\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Time Series Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Time series by season (since data is seasonal aggregates)\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df['season_year'] = df['season'] + ' ' + df['year'].astype(str)\n",
        "\n",
        "# Average by season and pollutant\n",
        "seasonal_avg = df.groupby(['season_year', 'pollutant'])['value'].mean().reset_index()\n",
        "# Create approximate date for plotting\n",
        "season_to_month = {'Summer': '06', 'Winter': '12', 'Spring': '03', 'Fall': '09'}\n",
        "seasonal_avg['plot_date'] = pd.to_datetime(\n",
        "    seasonal_avg['season_year'].str.split().str[1] + '-' + \n",
        "    seasonal_avg['season_year'].str.split().str[0].map(season_to_month) + '-01',\n",
        "    format='%Y-%m-%d', errors='coerce'\n",
        ")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "for pollutant in seasonal_avg['pollutant'].unique():\n",
        "    data = seasonal_avg[seasonal_avg['pollutant'] == pollutant].sort_values('plot_date')\n",
        "    ax.plot(data['plot_date'], data['value'], marker='o', label=pollutant, alpha=0.7, linewidth=2, markersize=6)\n",
        "\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Average Value')\n",
        "ax.set_title('Seasonal Average Air Quality by Pollutant Over Time')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Diurnal Cycle (Hourly Patterns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Note: This dataset contains seasonal aggregates, not hourly data\n",
        "# Instead, show seasonal patterns\n",
        "seasonal_pattern = df.groupby(['season', 'pollutant'])['value'].mean().reset_index()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "pivot = seasonal_pattern.pivot(index='pollutant', columns='season', values='value')\n",
        "pivot.plot(kind='bar', ax=ax, width=0.8)\n",
        "ax.set_xlabel('Pollutant')\n",
        "ax.set_ylabel('Average Value')\n",
        "ax.set_title('Seasonal Patterns: Average Air Quality by Season')\n",
        "ax.legend(title='Season')\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Note: This dataset contains seasonal aggregates, not hourly measurements.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Weekday vs Weekend Differences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Note: This dataset doesn't have weekday/weekend distinction (seasonal aggregates)\n",
        "# Instead, compare by year to show trends\n",
        "yearly_avg = df.groupby(['year', 'pollutant'])['value'].mean().reset_index()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "for pollutant in yearly_avg['pollutant'].unique():\n",
        "    data = yearly_avg[yearly_avg['pollutant'] == pollutant]\n",
        "    ax.plot(data['year'], data['value'], marker='o', label=pollutant, linewidth=2, markersize=8)\n",
        "\n",
        "ax.set_xlabel('Year')\n",
        "ax.set_ylabel('Average Value')\n",
        "ax.set_title('Yearly Trends: Average Air Quality by Pollutant')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Note: This dataset contains seasonal aggregates, so weekday/weekend comparison is not applicable.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Top Stations by Measurement Count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top stations by number of measurements\n",
        "station_counts = df.groupby(['station_id', 'station_name', 'borough']).size().reset_index(name='count')\n",
        "station_counts = station_counts.sort_values('count', ascending=False).head(15)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "ax.barh(range(len(station_counts)), station_counts['count'])\n",
        "ax.set_yticks(range(len(station_counts)))\n",
        "ax.set_yticklabels([f\"{row['station_name']} ({row['borough']})\" \n",
        "                     for _, row in station_counts.iterrows()])\n",
        "ax.set_xlabel('Number of Measurements')\n",
        "ax.set_title('Top 15 Stations by Measurement Count')\n",
        "ax.grid(True, alpha=0.3, axis='x')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Top 10 stations:\")\n",
        "print(station_counts.head(10)[['station_name', 'borough', 'count']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Distribution by Borough\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Average values by borough and pollutant\n",
        "borough_avg = df.groupby(['borough', 'pollutant'])['value'].mean().reset_index()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "pivot = borough_avg.pivot(index='borough', columns='pollutant', values='value')\n",
        "pivot.plot(kind='bar', ax=ax, width=0.8)\n",
        "ax.set_xlabel('Borough')\n",
        "ax.set_ylabel('Average Value')\n",
        "ax.set_title('Average Air Quality by Borough and Pollutant')\n",
        "ax.legend(title='Pollutant', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Value Distributions (Histograms)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Histograms by pollutant\n",
        "pollutants = df['pollutant'].unique()\n",
        "n_pollutants = len(pollutants)\n",
        "fig, axes = plt.subplots(n_pollutants, 1, figsize=(12, 4*n_pollutants))\n",
        "\n",
        "if n_pollutants == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for ax, pollutant in zip(axes, pollutants):\n",
        "    data = df[df['pollutant'] == pollutant]['value']\n",
        "    ax.hist(data, bins=50, alpha=0.7, edgecolor='black')\n",
        "    ax.set_xlabel('Value')\n",
        "    ax.set_ylabel('Frequency')\n",
        "    ax.set_title(f'Distribution of {pollutant}')\n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "    ax.axvline(data.mean(), color='red', linestyle='--', label=f'Mean: {data.mean():.2f}')\n",
        "    ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary statistics by pollutant\n",
        "summary = df.groupby('pollutant')['value'].agg([\n",
        "    'count', 'mean', 'std', 'min', 'max', 'median'\n",
        "]).round(2)\n",
        "print(\"Summary Statistics by Pollutant:\")\n",
        "print(summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dashboard Fields - Aggregations to Support\n",
        "\n",
        "Based on the EDA, here are the recommended aggregations and filters for the dashboard:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Filters:\n",
        "1. **Date Range**: Start date and end date picker\n",
        "2. **Pollutant**: Multi-select (PM2.5, PM10, O3, NO2, etc.)\n",
        "3. **Borough**: Multi-select (Manhattan, Brooklyn, Queens, Bronx, Staten Island)\n",
        "4. **Station**: Multi-select (filter by station_id or station_name)\n",
        "5. **Day Type**: Weekday vs Weekend toggle\n",
        "\n",
        "### Aggregations:\n",
        "1. **Temporal Aggregations**:\n",
        "   - Hourly averages (for diurnal cycle)\n",
        "   - Daily averages (for time series trends)\n",
        "   - Weekly averages\n",
        "   - Monthly averages\n",
        "   - Yearly averages\n",
        "\n",
        "2. **Spatial Aggregations**:\n",
        "   - By borough (average across stations in borough)\n",
        "   - By station (individual station trends)\n",
        "   - Cross-borough comparisons\n",
        "\n",
        "3. **Statistical Aggregations**:\n",
        "   - Mean, median, min, max\n",
        "   - Percentiles (25th, 75th, 95th)\n",
        "   - Standard deviation\n",
        "\n",
        "### Visualizations:\n",
        "1. **Time Series**: Line chart showing trends over time (daily/weekly/monthly)\n",
        "2. **Diurnal Cycle**: Hourly averages by pollutant\n",
        "3. **Borough Comparison**: Bar chart or heatmap comparing boroughs\n",
        "4. **Station Map**: Map showing station locations (if lat/lon available)\n",
        "5. **Distribution**: Histogram or box plot of values\n",
        "6. **Weekday vs Weekend**: Side-by-side comparison\n",
        "\n",
        "### Key Metrics to Display:\n",
        "- Current average by pollutant and borough\n",
        "- Peak hours for each pollutant\n",
        "- Worst-performing stations/boroughs\n",
        "- Trend direction (improving/worsening)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
